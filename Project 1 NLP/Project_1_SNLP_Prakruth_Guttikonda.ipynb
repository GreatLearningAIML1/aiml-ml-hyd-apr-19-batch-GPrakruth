{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import stopwords,wordnet\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction import text \n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"blogtext.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'gender', 'age', 'topic', 'sign', 'date', 'text'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(681284, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    Info has been found (+/- 100 pages,...\n",
       "1                    These are the team members:   Drewe...\n",
       "2                    In het kader van kernfusie op aarde...\n",
       "3                          testing!!!  testing!!!          \n",
       "4                      Thanks to Yahoo!'s Toolbar I can ...\n",
       "                                ...                        \n",
       "681279           Dear Susan,  I could write some really ...\n",
       "681280           Dear Susan,  'I have the second yeast i...\n",
       "681281           Dear Susan,  Your 'boyfriend' is fuckin...\n",
       "681282           Dear Susan:    Just to clarify, I am as...\n",
       "681283           Hey everybody...and Susan,  You might a...\n",
       "Name: text, Length: 681284, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data.head(9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "new_data['label'] = new_data[new_data.columns[1:5]].apply(lambda x: (','.join(x.dropna().astype(str))),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "      <td>male,15,Student,Leo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "      <td>male,15,Student,Leo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "      <td>male,15,Student,Leo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "      <td>male,15,Student,Leo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "      <td>male,33,InvestmentBanking,Aquarius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8995</td>\n",
       "      <td>3477296</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Virgo</td>\n",
       "      <td>17,July,2004</td>\n",
       "      <td>wah! how cold was it today? *...</td>\n",
       "      <td>male,15,Student,Virgo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8996</td>\n",
       "      <td>3477296</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Virgo</td>\n",
       "      <td>17,July,2004</td>\n",
       "      <td>Could someone give me some su...</td>\n",
       "      <td>male,15,Student,Virgo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8997</td>\n",
       "      <td>3477296</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Virgo</td>\n",
       "      <td>17,July,2004</td>\n",
       "      <td>I am blogging here tonight on...</td>\n",
       "      <td>male,15,Student,Virgo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8998</td>\n",
       "      <td>3477296</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Virgo</td>\n",
       "      <td>16,July,2004</td>\n",
       "      <td>'It isn't pollution that's ha...</td>\n",
       "      <td>male,15,Student,Virgo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8999</td>\n",
       "      <td>3477296</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Virgo</td>\n",
       "      <td>16,July,2004</td>\n",
       "      <td>Seems like everyone these day...</td>\n",
       "      <td>male,15,Student,Virgo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id gender  age              topic      sign          date  \\\n",
       "0     2059027   male   15            Student       Leo   14,May,2004   \n",
       "1     2059027   male   15            Student       Leo   13,May,2004   \n",
       "2     2059027   male   15            Student       Leo   12,May,2004   \n",
       "3     2059027   male   15            Student       Leo   12,May,2004   \n",
       "4     3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "...       ...    ...  ...                ...       ...           ...   \n",
       "8995  3477296   male   15            Student     Virgo  17,July,2004   \n",
       "8996  3477296   male   15            Student     Virgo  17,July,2004   \n",
       "8997  3477296   male   15            Student     Virgo  17,July,2004   \n",
       "8998  3477296   male   15            Student     Virgo  16,July,2004   \n",
       "8999  3477296   male   15            Student     Virgo  16,July,2004   \n",
       "\n",
       "                                                   text  \\\n",
       "0                Info has been found (+/- 100 pages,...   \n",
       "1                These are the team members:   Drewe...   \n",
       "2                In het kader van kernfusie op aarde...   \n",
       "3                      testing!!!  testing!!!             \n",
       "4                  Thanks to Yahoo!'s Toolbar I can ...   \n",
       "...                                                 ...   \n",
       "8995                   wah! how cold was it today? *...   \n",
       "8996                   Could someone give me some su...   \n",
       "8997                   I am blogging here tonight on...   \n",
       "8998                   'It isn't pollution that's ha...   \n",
       "8999                   Seems like everyone these day...   \n",
       "\n",
       "                                   label  \n",
       "0                    male,15,Student,Leo  \n",
       "1                    male,15,Student,Leo  \n",
       "2                    male,15,Student,Leo  \n",
       "3                    male,15,Student,Leo  \n",
       "4     male,33,InvestmentBanking,Aquarius  \n",
       "...                                  ...  \n",
       "8995               male,15,Student,Virgo  \n",
       "8996               male,15,Student,Virgo  \n",
       "8997               male,15,Student,Virgo  \n",
       "8998               male,15,Student,Virgo  \n",
       "8999               male,15,Student,Virgo  \n",
       "\n",
       "[9000 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = new_data.drop(columns=['gender','age','topic','sign','id','date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "      <td>male,15,Student,Leo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "      <td>male,15,Student,Leo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "      <td>male,15,Student,Leo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "      <td>male,15,Student,Leo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "      <td>male,33,InvestmentBanking,Aquarius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8995</td>\n",
       "      <td>wah! how cold was it today? *...</td>\n",
       "      <td>male,15,Student,Virgo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8996</td>\n",
       "      <td>Could someone give me some su...</td>\n",
       "      <td>male,15,Student,Virgo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8997</td>\n",
       "      <td>I am blogging here tonight on...</td>\n",
       "      <td>male,15,Student,Virgo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8998</td>\n",
       "      <td>'It isn't pollution that's ha...</td>\n",
       "      <td>male,15,Student,Virgo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8999</td>\n",
       "      <td>Seems like everyone these day...</td>\n",
       "      <td>male,15,Student,Virgo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0                Info has been found (+/- 100 pages,...   \n",
       "1                These are the team members:   Drewe...   \n",
       "2                In het kader van kernfusie op aarde...   \n",
       "3                      testing!!!  testing!!!             \n",
       "4                  Thanks to Yahoo!'s Toolbar I can ...   \n",
       "...                                                 ...   \n",
       "8995                   wah! how cold was it today? *...   \n",
       "8996                   Could someone give me some su...   \n",
       "8997                   I am blogging here tonight on...   \n",
       "8998                   'It isn't pollution that's ha...   \n",
       "8999                   Seems like everyone these day...   \n",
       "\n",
       "                                   label  \n",
       "0                    male,15,Student,Leo  \n",
       "1                    male,15,Student,Leo  \n",
       "2                    male,15,Student,Leo  \n",
       "3                    male,15,Student,Leo  \n",
       "4     male,33,InvestmentBanking,Aquarius  \n",
       "...                                  ...  \n",
       "8995               male,15,Student,Virgo  \n",
       "8996               male,15,Student,Virgo  \n",
       "8997               male,15,Student,Virgo  \n",
       "8998               male,15,Student,Virgo  \n",
       "8999               male,15,Student,Virgo  \n",
       "\n",
       "[9000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000\n"
     ]
    }
   ],
   "source": [
    "print(len(new_data.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'           Info has been found (+/- 100 pages, and 4.5 MB of .pdf files) Now i have to wait untill our team leader has processed it and learns html.         '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "l1 = ('btw','zza','zzzexy','zzzzz','youuuuu')\n",
    "nlp.Defaults.stop_words.add(l1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(len(new_data.text)):\n",
    " #   new_data.text[i] = new_data.text[i].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  Info has been found (+/- 100 pages,...\n",
       "1                  These are the team members:   Drewe...\n",
       "2                  In het kader van kernfusie op aarde...\n",
       "3                        testing!!!  testing!!!          \n",
       "4                    Thanks to Yahoo!'s Toolbar I can ...\n",
       "                              ...                        \n",
       "8995                     wah! how cold was it today? *...\n",
       "8996                     Could someone give me some su...\n",
       "8997                     I am blogging here tonight on...\n",
       "8998                     'It isn't pollution that's ha...\n",
       "8999                     Seems like everyone these day...\n",
       "Name: text, Length: 9000, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     object\n",
       "label    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(new_data.text)):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    new_data.text[i] = new_data.text[i].lower()\n",
    "    word_tokens = tokenizer.tokenize(new_data.text[i])\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stopwords.words('english')] \n",
    "    filtered_sentence = [] \n",
    "    for w in word_tokens: \n",
    "        if w not in (nlp.Defaults.stop_words or string.punctuation):\n",
    "            #if not w.isalpha():\n",
    "            filtered_sentence.append(re.sub(r\"[^a-zA-Z0-9]+\", ' ',w ))\n",
    "   \n",
    "    new_data.text[i] = \" \".join(filtered_sentence)\n",
    "#print(word_tokens) \n",
    "#    print(new_data.text_new[i])\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       info found 100 pages 4 5 mb pdf files wait unt...\n",
       "1       team members drewes van der laag urllink mail ...\n",
       "2       het kader van kernfusie op aarde maak je eigen...\n",
       "3                                         testing testing\n",
       "4       thanks yahoo s toolbar capture urls popups mea...\n",
       "                              ...                        \n",
       "8995    wah cold today brrr wake 7 worth grins said sl...\n",
       "8996    suggestions music dls im open asian music look...\n",
       "8997    blogging tonight request andy know blog tonigh...\n",
       "8998    isn t pollution s harming environment s impuri...\n",
       "8999    like days turning religion times peril terror ...\n",
       "Name: text, Length: 9000, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_data.text\n",
    "Y = new_data.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=524)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "# define a function that accepts a vectorizer and calculates the accuracy\n",
    "def tokenize_test(vect):\n",
    "    X_train_dtm = vect.fit_transform(X_train)\n",
    "    print('Features: ', X_train_dtm.shape[1])\n",
    "    X_test_dtm = vect.transform(X_test)\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X_train_dtm, y_train)\n",
    "    #feature = nb.feature_count_\n",
    "    #print(\"NB feature shape\", feature)\n",
    "   # print(nb.feature_count_.shape)\n",
    "    y_train_pred = nb.predict(X_train_dtm)\n",
    "    y_pred_class = nb.predict(X_test_dtm)\n",
    "    print('Train Accuracy for NB : ', metrics.accuracy_score(y_train,y_train_pred))\n",
    "    print('Test Accuracy for NB: ', metrics.accuracy_score(y_test, y_pred_class))\n",
    "    logreg = LogisticRegression(C=1e9)\n",
    "    logreg.fit(X_train_dtm, y_train)\n",
    "    y_pred_class_LR = logreg.predict(X_test_dtm)\n",
    "#print(metrics.accuracy_score(y_test, y_pred_class))\n",
    "    y_train_LR = logreg.predict(X_train_dtm)\n",
    "    print('Train Accuracy for LR: ',metrics.accuracy_score(y_train, y_train_LR))\n",
    "    print('Test Accuracy for LR: ',metrics.accuracy_score(y_test, y_pred_class_LR))\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  418363\n",
      "Train Accuracy for NB :  0.7691851851851852\n",
      "Test Accuracy for NB:  0.3671111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy for LR:  0.9948148148148148\n",
      "Test Accuracy for LR:  0.49777777777777776\n"
     ]
    }
   ],
   "source": [
    "# include 1-grams and 2-grams\n",
    "vect = CountVectorizer(ngram_range=(1, 2))\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  418363\n",
      "Train Accuracy for NB :  0.7691851851851852\n",
      "Test Accuracy for NB:  0.3671111111111111\n"
     ]
    }
   ],
   "source": [
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "print('Features: ', X_train_dtm.shape[1])\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)\n",
    "    #feature = nb.feature_count_\n",
    "    #print(\"NB feature shape\", feature)\n",
    "   # print(nb.feature_count_.shape)\n",
    "y_train_pred = nb.predict(X_train_dtm)\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "print('Train Accuracy for NB : ', metrics.accuracy_score(y_train,y_train_pred))\n",
    "print('Test Accuracy for NB: ', metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00 newton', '00 night', '00 nospamyahoo', '00 ok', '00 ouch', '00 plus', '00 pm', '00 presentations', '00 rarely', '00 ravenwood', '00 recently', '00 said', '00 saw', '00 sec', '00 showing', '00 speeding', '00 store', '00 sumber', '00 supposed', '00 taken', '00 tcr1', '00 teh', '00 time', '00 tired', '00 today', '00 tomorrow', '00 truth', '00 unit', '00 usher', '00 ve', '00 week', '00 woke', '00 yahoo', '00 yes', '000', '000 00', '000 000', '000 100', '000 1998', '000 36', '000 acre', '000 active', '000 address', '000 albums', '000 amish', '000 animals', '000 automobile', '000 bad', '000 btu', '000 cds', '000 checks', '000 companion', '000 compared', '000 copies', '000 cops', '000 country', '000 dangerous', '000 dollar', '000 dollars', '000 drop', '000 end', '000 english', '000 excited', '000 fact', '000 families', '000 far', '000 feet', '000 ferrari', '000 fight', '000 figure', '000 financial', '000 fix', '000 flights', '000 fucking', '000 ground', '000 guess', '000 head', '000 hearing', '000 households', '000 human', '000 insane', '000 insurance', '000 iraqi', '000 japanese', '000 jesus', '000 jobs', '000 kuwait', '000 lakes', '000 layers', '000 loan', '000 makes', '000 miles', '000 month', '000 new', '000 nutjobs', '000 options', '000 order', '000 pages', '000 payment', '000 people', '000 piece', '000 pledge', '000 pound', '000 pounds', '000 protestors', '000 relief', '000 renovation', '000 rich', '000 said', '000 sentenced', '000 shit', '000 signatures', '000 slaughtered', '000 soldiers', '000 square', '000 strangers', '000 subject', '000 texas', '000 times', '000 troops', '000 united', '000 ve', '000 visitors', '000 votes', '000 wants', '000 won', '000 words', '000 worth', '000 year', '000 years', '000 yes', '0000', '0000 blinking', '000001', '000001 maybe', '000001 zbaras', '000058', '000058 html', '000miles', '000miles away', '000th', '000th time', '001', '001 dollars', '001 jillian', '002', '002 middle', '003', '003 love', '004', '004 nickname', '005', '005 gender', '006', '006 age', '007', '007 birthday', '007 game', '007 jersey', '008', '008 height', '009', '009 hair', '00am', '00am early', '00am going', '00am know', '00am ride', '00am somebody', '00am today', '00pm', '00pm check', '00pm darn', '00pm especially', '00pm figured', '00pm hahahhahaha', '00pm played', '00pm till', '01', '01 08', '01 2003', '01 22', '01 informs', '01 known', '01 role', '01 televive', '01 underworld', '010', '010 eye', '0100', '0100 hrs', '010203', '010203 hehehe', '011', '011 race', '012', '012 glasses', '01234', '01234 time', '0128', '0128 euro', '013', '013 braces', '014', '014 949', '014 hair', '015', '015 born', '016', '016 current', '017', '017 zodiac', '018', '018 languages', '019', '019 nationality', '02', '02 00', '02 18', '02 2002', '02 23', '02 25', '02 56', '02 added', '02 argue', '02 deadbeat', '02 faced', '02 hope', '02 impression', '02 like', '02 ll', '02 lott', '02 personal', '02 pet', '02 pm', '02 republicans', '02 statement', '02 urllink', '02 wilding', '020', '020 bad', '021', '021 piercings', '022', '022 piercings', '023', '023 tattoos', '024', '024 tattoos', '025', '025 today', '0250', '0250 hentoff', '026', '026 time', '027', '027 ready', '028', '028 mother', '029', '029 father', '03', '03 03', '03 11', '03 15', '03 16', '03 22', '03 31', '03 41', '03 afternoon', '03 calvin', '03 chewbacca', '03 confused', '03 deadbeat', '03 deal', '03 fiesta', '03 focus', '03 god', '03 harmony', '03 hate', '03 knows', '03 life', '03 love', '03 moz', '03 pass', '03 pm', '03 sarah', '03 sigh', '03 spending', '03 state', '03 won', '03 working', '03 world', '03 wouldn', '030', '030 step', '031', '031 brother', '032', '032 sister', '0327554', '033', '033 favorite', '034', '034 favorite', '0346', '0346 otis', '035', '035 favorite', '036', '036 worst', '037', '037 best', '038', '038 parents', '039', '039 family', '04', '04 04', '04 10', '04 16', '04 19', '04 added', '04 apocalypse', '04 asses', '04 better', '04 brainer', '04 bush', '04 capitalize', '04 cia', '04 compassionate', '04 couldnt', '04 day', '04 don', '04 economy', '04 email', '04 going', '04 gooder', '04 heart', '04 leave', '04 liked', '04 making', '04 ntu', '04 pineapple', '04 president', '04 putting', '04 revolutionary', '04 season', '04 seeing', '04 state', '04 thank', '04 thanks', '04 ticket', '04 time', '04 told', '04 trustworthy', '04 truth', '04 vote', '04 wars', '040', '040 pets', '0400', '0400 starin', '041', '041 names', '042', '042 kind', '043', '043 school', '0431', '0431 travsd', '044', '044 drop', '045', '045 current', '046', '046 favorite', '047', '047 favorite', '048', '048 favorite', '049', '049 favorite', '05', '05 04', '05 06', '05 07', '05 11', '05 13', '05 16', '05 22', '05 35', '05 44', '05 cried', '05 drugwar', '05 gives', '05 greeted', '05 jul', '05 little', '05 makes', '05 quickly', '05 sweet', '05 thursday', '05 trouble', '05 watched', '050', '050 favorite', '0505', '0505 189', '051', '051 favorite', '052', '052 buy', '053', '053 play', '054', '054 extracurricular', '055', '055 popular', '056', '056 favorite', '057', '057 favorite', '058', '058 favorite', '059', '059 favorite', '05pm', '05pm day', '06', '06 03', '06 04', '06 05', '06 07', '06 09', '06 10', '06 11', '06 12', '06 19', '06 case', '06 cloud', '06 hard', '06 pm', '06 pst', '06 slave', '06 sure', '06 type', '060', '060 humiliating', '0600']\n"
     ]
    }
   ],
   "source": [
    "# features names\n",
    "feature_names = vect.get_feature_names()\n",
    "print(feature_names[50:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2122    male,35,Technology,Aries\n",
       "5676     female,27,indUnk,Taurus\n",
       "7396       male,36,Fashion,Aries\n",
       "1668    male,35,Technology,Aries\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6750"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = y_train.apply(lambda x : pd.value_counts(x.split(\",\"))).sum(axis = 0).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'35': 1753.0,\n",
       " 'Technology': 1970.0,\n",
       " 'Aries': 3155.0,\n",
       " 'male': 4160.0,\n",
       " '27': 665.0,\n",
       " 'female': 2590.0,\n",
       " 'Taurus': 588.0,\n",
       " 'indUnk': 2051.0,\n",
       " '36': 1298.0,\n",
       " 'Fashion': 1230.0,\n",
       " 'Pisces': 288.0,\n",
       " 'Internet': 89.0,\n",
       " 'Aquarius': 301.0,\n",
       " '33': 102.0,\n",
       " 'InvestmentBanking': 54.0,\n",
       " '24': 346.0,\n",
       " 'Engineering': 102.0,\n",
       " 'Libra': 372.0,\n",
       " 'Scorpio': 672.0,\n",
       " '17': 745.0,\n",
       " 'Education': 184.0,\n",
       " '34': 414.0,\n",
       " 'Student': 689.0,\n",
       " '14': 133.0,\n",
       " '25': 270.0,\n",
       " 'Sagittarius': 664.0,\n",
       " 'Cancer': 230.0,\n",
       " 'Capricorn': 101.0,\n",
       " 'Gemini': 107.0,\n",
       " '15': 416.0,\n",
       " '26': 143.0,\n",
       " 'Leo': 163.0,\n",
       " '23': 156.0,\n",
       " 'Marketing': 9.0,\n",
       " 'Banking': 14.0,\n",
       " 'BusinessServices': 62.0,\n",
       " 'Sports-Recreation': 53.0,\n",
       " '16': 126.0,\n",
       " 'Religion': 8.0,\n",
       " '41': 15.0,\n",
       " '13': 29.0,\n",
       " 'Communications-Media': 76.0,\n",
       " '39': 60.0,\n",
       " 'Virgo': 109.0,\n",
       " 'Consulting': 10.0,\n",
       " 'Law': 6.0,\n",
       " 'Science': 45.0,\n",
       " '42': 9.0,\n",
       " 'Automotive': 7.0,\n",
       " 'Arts': 26.0,\n",
       " '38': 37.0,\n",
       " 'Non-Profit': 57.0,\n",
       " '37': 13.0,\n",
       " '43': 4.0,\n",
       " 'Accounting': 4.0,\n",
       " '45': 10.0,\n",
       " '44': 2.0,\n",
       " 'Museums-Libraries': 2.0,\n",
       " 'Publishing': 2.0,\n",
       " '46': 3.0,\n",
       " '40': 1.0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mlb = mlb.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_mlb = mlb.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(solver = 'lbfgs',random_state= 111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=111, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 1],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 1],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_mlb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 0 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 28 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 32 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 38 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\multiclass.py:76: UserWarning: Label 39 is present in all training examples.\n",
      "  str(classes[c]))\n",
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_dtm,y_train_mlb)\n",
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_clf = clf.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2653333333333333\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test_mlb,y_pred_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2250\n",
      "           1       0.71      0.19      0.30        64\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.86      0.46      0.60       542\n",
      "           4       0.76      0.35      0.48       526\n",
      "           5       0.80      0.83      0.81      1241\n",
      "           6       0.88      0.36      0.51       331\n",
      "           7       0.76      0.55      0.64       797\n",
      "           8       0.89      0.48      0.62       498\n",
      "           9       0.83      0.33      0.47       505\n",
      "          10       0.75      0.33      0.46         9\n",
      "          11       1.00      0.11      0.19        19\n",
      "          12       0.79      0.78      0.78      1129\n",
      "          13       0.89      0.19      0.31        43\n",
      "          14       0.83      0.16      0.27       158\n",
      "          15       0.76      0.15      0.25        87\n",
      "          16       0.95      0.54      0.69       392\n",
      "          17       1.00      0.06      0.11        33\n",
      "          18       0.67      0.27      0.38        45\n",
      "          19       0.67      0.22      0.33       186\n",
      "          20       1.00      0.04      0.08        24\n",
      "          21       0.00      0.00      0.00        14\n",
      "          22       0.97      0.31      0.47       105\n",
      "          23       1.00      0.29      0.44        28\n",
      "          24       0.83      0.49      0.62       717\n",
      "          25       0.76      0.67      0.71       823\n",
      "          26       0.79      0.40      0.53       708\n",
      "          27       1.00      0.03      0.05        40\n",
      "          28       1.00      1.00      1.00      2250\n",
      "          29       0.65      0.20      0.31       118\n",
      "          30       0.79      0.74      0.76      1141\n",
      "          31       0.85      0.62      0.72      1030\n",
      "          32       1.00      1.00      1.00      2250\n",
      "          33       0.84      0.58      0.68       896\n",
      "          34       0.78      0.60      0.68       935\n",
      "          35       0.80      0.78      0.79      1031\n",
      "          36       0.97      1.00      0.98      2172\n",
      "          37       0.79      0.43      0.55       727\n",
      "          38       1.00      1.00      1.00      2250\n",
      "          39       1.00      1.00      1.00      2250\n",
      "          40       0.99      1.00      1.00      2230\n",
      "          41       0.83      0.89      0.86      1501\n",
      "          42       0.78      0.20      0.32       288\n",
      "          43       0.78      0.21      0.33       101\n",
      "          44       0.94      0.99      0.97      2072\n",
      "          45       0.84      0.94      0.89      1681\n",
      "          46       0.79      0.49      0.60       626\n",
      "          47       0.80      0.52      0.63       763\n",
      "          48       0.89      0.17      0.28        48\n",
      "          49       0.00      0.00      0.00         5\n",
      "          50       0.79      0.56      0.66       637\n",
      "\n",
      "   micro avg       0.91      0.79      0.84     38316\n",
      "   macro avg       0.80      0.48      0.55     38316\n",
      "weighted avg       0.89      0.79      0.82     38316\n",
      " samples avg       0.90      0.79      0.84     38316\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_mlb, y_pred_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7864627878473044"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.average_precision_score(y_test_mlb, y_pred_clf,average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recall score for  average type Micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7916797160455162"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#metrics.recall_score(y_test_mlb, y_pred_clf)\n",
    "metrics.recall_score(y_test_mlb, y_pred_clf, labels=None, pos_label=1, average='micro', sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recall score for  average type Macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4801094213369808"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metrics.recall_score(y_test_mlb, y_pred_clf, labels=None, pos_label=1, average='macro', sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recall score for  average type weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7916797160455162"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metrics.recall_score(y_test_mlb, y_pred_clf, labels=None, pos_label=1, average='weighted', sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[   0,    0],\n",
       "        [   0, 2250]],\n",
       "\n",
       "       [[2181,    5],\n",
       "        [  52,   12]],\n",
       "\n",
       "       [[2250,    0],\n",
       "        [   0,    0]],\n",
       "\n",
       "       [[1668,   40],\n",
       "        [ 292,  250]],\n",
       "\n",
       "       [[1664,   60],\n",
       "        [ 341,  185]],\n",
       "\n",
       "       [[ 749,  260],\n",
       "        [ 210, 1031]],\n",
       "\n",
       "       [[1903,   16],\n",
       "        [ 212,  119]],\n",
       "\n",
       "       [[1313,  140],\n",
       "        [ 356,  441]],\n",
       "\n",
       "       [[1723,   29],\n",
       "        [ 259,  239]],\n",
       "\n",
       "       [[1712,   33],\n",
       "        [ 340,  165]],\n",
       "\n",
       "       [[2240,    1],\n",
       "        [   6,    3]],\n",
       "\n",
       "       [[2231,    0],\n",
       "        [  17,    2]],\n",
       "\n",
       "       [[ 881,  240],\n",
       "        [ 249,  880]],\n",
       "\n",
       "       [[2206,    1],\n",
       "        [  35,    8]],\n",
       "\n",
       "       [[2087,    5],\n",
       "        [ 133,   25]],\n",
       "\n",
       "       [[2159,    4],\n",
       "        [  74,   13]],\n",
       "\n",
       "       [[1846,   12],\n",
       "        [ 180,  212]],\n",
       "\n",
       "       [[2217,    0],\n",
       "        [  31,    2]],\n",
       "\n",
       "       [[2199,    6],\n",
       "        [  33,   12]],\n",
       "\n",
       "       [[2044,   20],\n",
       "        [ 146,   40]],\n",
       "\n",
       "       [[2226,    0],\n",
       "        [  23,    1]],\n",
       "\n",
       "       [[2236,    0],\n",
       "        [  14,    0]],\n",
       "\n",
       "       [[2144,    1],\n",
       "        [  72,   33]],\n",
       "\n",
       "       [[2222,    0],\n",
       "        [  20,    8]],\n",
       "\n",
       "       [[1461,   72],\n",
       "        [ 366,  351]],\n",
       "\n",
       "       [[1252,  175],\n",
       "        [ 269,  554]],\n",
       "\n",
       "       [[1465,   77],\n",
       "        [ 424,  284]],\n",
       "\n",
       "       [[2210,    0],\n",
       "        [  39,    1]],\n",
       "\n",
       "       [[   0,    0],\n",
       "        [   0, 2250]],\n",
       "\n",
       "       [[2119,   13],\n",
       "        [  94,   24]],\n",
       "\n",
       "       [[ 882,  227],\n",
       "        [ 301,  840]],\n",
       "\n",
       "       [[1111,  109],\n",
       "        [ 389,  641]],\n",
       "\n",
       "       [[   0,    0],\n",
       "        [   0, 2250]],\n",
       "\n",
       "       [[1255,   99],\n",
       "        [ 379,  517]],\n",
       "\n",
       "       [[1161,  154],\n",
       "        [ 375,  560]],\n",
       "\n",
       "       [[1016,  203],\n",
       "        [ 225,  806]],\n",
       "\n",
       "       [[  10,   68],\n",
       "        [   4, 2168]],\n",
       "\n",
       "       [[1439,   84],\n",
       "        [ 416,  311]],\n",
       "\n",
       "       [[   0,    0],\n",
       "        [   0, 2250]],\n",
       "\n",
       "       [[   0,    0],\n",
       "        [   0, 2250]],\n",
       "\n",
       "       [[   0,   20],\n",
       "        [   0, 2230]],\n",
       "\n",
       "       [[ 482,  267],\n",
       "        [ 169, 1332]],\n",
       "\n",
       "       [[1946,   16],\n",
       "        [ 231,   57]],\n",
       "\n",
       "       [[2143,    6],\n",
       "        [  80,   21]],\n",
       "\n",
       "       [[  52,  126],\n",
       "        [  15, 2057]],\n",
       "\n",
       "       [[ 276,  293],\n",
       "        [ 102, 1579]],\n",
       "\n",
       "       [[1541,   83],\n",
       "        [ 321,  305]],\n",
       "\n",
       "       [[1385,  102],\n",
       "        [ 363,  400]],\n",
       "\n",
       "       [[2201,    1],\n",
       "        [  40,    8]],\n",
       "\n",
       "       [[2245,    0],\n",
       "        [   5,    0]],\n",
       "\n",
       "       [[1517,   96],\n",
       "        [ 280,  357]]], dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.multilabel_confusion_matrix(y_test_mlb, y_pred_clf,sample_weight=None,labels=None,samplewise=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision, recall and F1 score for Micro average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9055465997970028, 0.7916797160455162, 0.8447934943047317, None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_recall_fscore_support(y_test_mlb, y_pred_clf, beta=1.0, average='micro', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision, recall and F1 score for Macro average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\pg\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8046078147741718, 0.4801094213369808, 0.55133580650704, None)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_recall_fscore_support(y_test_mlb, y_pred_clf, beta=1.0, average='macro', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision, recall and F1 score for Weighted average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8928966542891479, 0.7916797160455162, 0.8233007112390947, None)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.precision_recall_fscore_support(y_test_mlb, y_pred_clf, beta=1.0, average='weighted', warn_for=('precision', 'recall', 'f-score'), sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "        1, 1, 0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "        1, 1, 1, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_clf[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "        1, 1, 0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_mlb[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
